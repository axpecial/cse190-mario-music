{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSE 190 Project\n",
    "\n",
    "Name: Andy Duong  \n",
    "PID: A13528452"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Ask anyone in this day and age if they know who Mario is. You'll probably find that most if not all people can recognize the name. Even more might immediately recognize the tune of the original Super Mario Bros game. All of the these pieces were written by a composer by the name of Koji Kondo. Koji is a lead composer at Nintendo and has led the creation of soundtracks for multiple Mario and even Legend of Zelda games. Personally, his music is very memorable to me because I grew up playing Mario games. I wanted to take this opportunity to see if a network was capable of emulating the type of creativity required to compose some interesting songs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "In this project, I will be using a generative adversarial network (GAN) to generate new Mario music. The GAN framework consists of 2 separate networks, each with their own role: a generator and a discriminator.\n",
    "\n",
    "A generator is responsible for converting the latent vector into a prediciton. A discriminator is responsible for validating the predictions of the generator. A generator starts with a random latent vector and a random set of weights in its internal nodes. The discriminator then tries to distinguish the generated \"fake\" output from the training \"real\" data.\n",
    "\n",
    "At start-up, both networks incur high levels of error, but as training continues, the generator and discriminator should be learning at around the same rate. There is a feedback loop between these two networks that allows them to improve each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rF2x3qooyBTI"
   },
   "source": [
    "# Generative Adversarial Network Architecture\n",
    "\n",
    "This code is adapted from a [tutorial](https://towardsdatascience.com/generating-pokemon-inspired-music-from-neural-networks-bc240014132) on a similar project, in which the researchers use a GAN to generate Pokemon music. I adapted their code to work with input MIDI files that I found.\n",
    "\n",
    "The MIDI files were songs from several Mario games.\n",
    "* [Super Mario Bros](http://www.mariopiano.com/midi-sound-file-ending-theme.html): Overworld Main Theme, Rescue Fanfare, Starman Theme, Underwater Theme, Underworld Theme, Castle Theme, Ending Theme\n",
    "* [Paper Mario 64](https://www.khinsider.com/midi/n64/paper-mario): Crystal Palace, Koopa Village, Starborn Valley, Title Screen, Tubba Blubba Battle, Yoshi Island 2\n",
    "* [Super Mario 64](https://www.khinsider.com/midi/n64/super-mario-64): Cool Cool Mountain, Dire Dire Docks, Koopa Theme, Lava Lava Island, Title Theme, Inside the Castle Walls, Bob-omb Battlefield\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Below is all of the code that was used to generate the output files. The GitHub link is TODO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e1_Y75QXJS6h"
   },
   "source": [
    "### Import TensorFlow and other libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WZKbyU2-AiY-"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wx-zNbLqB4K8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YfIk2es3hJEd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/Users/andyduong/opt/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "import pickle\n",
    "from music21 import converter, instrument, note, chord, stream\n",
    "from keras.layers import Input, Dense, Reshape, Dropout, LSTM, Bidirectional\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iYn4MdZnKCey"
   },
   "source": [
    "### Load and prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of notes passed into the model so it can predict the subsequent notes\n",
    "SEQ_INPUT_LEN = 100\n",
    "SEQ_INPUT_SHAPE = (SEQ_INPUT_LEN, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_notes():\n",
    "    notes = []\n",
    "    for file in glob.glob(\"mario_midi/**/*.mid\", recursive=True):\n",
    "        midi = converter.parse(file)\n",
    "        print(\"Parsing %s\" % file)\n",
    "        notes_to_parse = None\n",
    "        try: # file has instrument parts\n",
    "            s2 = instrument.partitionByInstrument(midi)\n",
    "            notes_to_parse = s2.parts[0].recurse() \n",
    "        except: # file has notes in a flat structure\n",
    "            notes_to_parse = midi.flat.notes\n",
    "\n",
    "        for element in notes_to_parse:\n",
    "            if isinstance(element, note.Note):\n",
    "                notes.append(str(element.pitch))\n",
    "            elif isinstance(element, chord.Chord):\n",
    "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "\n",
    "    pickle.dump(notes, open('notes.p', 'wb'))\n",
    "\n",
    "    return notes\n",
    "\n",
    "def prepare_sequences(notes, n_vocab):\n",
    "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
    "    sequence_length = SEQ_INPUT_LEN \n",
    "\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    network_input = []\n",
    "    network_output = []\n",
    "\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "        network_input.append([note_to_int[char] for char in sequence_in])\n",
    "        network_output.append(note_to_int[sequence_out])\n",
    "\n",
    "    n_patterns = len(network_input)\n",
    "\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    # normalize input between -1 and 1\n",
    "    network_input = (network_input - float(n_vocab)/2) / (float(n_vocab)/2)\n",
    "    \n",
    "    network_output = np_utils.to_categorical(network_output)\n",
    "\n",
    "    return (network_input, network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing mario_midi/Mario 64/lavalava-island.mid\n",
      "Parsing mario_midi/Mario 64/inside-the-castle-walls.mid\n",
      "Parsing mario_midi/Mario 64/course-1-bob-omb-battlefield-super-mario-64-main-theme-.mid\n",
      "Parsing mario_midi/Mario 64/koopa-s-theme.mid\n",
      "Parsing mario_midi/Mario 64/dire-dire-docks.mid\n",
      "Parsing mario_midi/Mario 64/title-theme.mid\n",
      "Parsing mario_midi/Mario 64/cool-cool-mountain.mid\n",
      "Parsing mario_midi/Paper Mario 64/title-screen.mid\n",
      "Parsing mario_midi/Paper Mario 64/tubba-blubba-battle.mid\n",
      "Parsing mario_midi/Paper Mario 64/yoshi-island-2-.mid\n",
      "Parsing mario_midi/Paper Mario 64/koopa-village.mid\n",
      "Parsing mario_midi/Paper Mario 64/starborn-valley.mid\n",
      "Parsing mario_midi/Paper Mario 64/crystal-palace.mid\n",
      "Parsing mario_midi/Super Mario Bros/Mario-Sheet-Music-Starman-Theme.mid\n",
      "Parsing mario_midi/Super Mario Bros/Mario-Sheet-Music-Ending-Theme.mid\n",
      "Parsing mario_midi/Super Mario Bros/Mario-Sheet-Music-Underworld-Theme.mid\n",
      "Parsing mario_midi/Super Mario Bros/Mario-Sheet-Music-Overworld-Main-Theme.mid\n",
      "Parsing mario_midi/Super Mario Bros/Mario-Sheet-Music-Castle-Theme.mid\n",
      "Parsing mario_midi/Super Mario Bros/Mario-Sheet-Music-Rescue-Fanfare.mid\n",
      "Parsing mario_midi/Super Mario Bros/Mario-Sheet-Music-Underwater-Theme.mid\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'C#5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'C#5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'C#5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'C#5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'C#5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'C#5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'C#5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'C#5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'C#5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'C#5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'D3',\n",
       " 'E4',\n",
       " 'A3',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'G3',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'C#5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'C#5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'C#5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'C#5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'C#5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'C#5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'C#5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'C#5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'C#5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'C#5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'C#5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'C#5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'C#5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'C#5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'C#5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'C#5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'D5',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'E4',\n",
       " 'C4',\n",
       " 'F4',\n",
       " 'B3',\n",
       " 'E4',\n",
       " 'B-3',\n",
       " 'E-4',\n",
       " 'A3',\n",
       " 'E4',\n",
       " 'G3',\n",
       " 'A4',\n",
       " 'F#3',\n",
       " 'C5',\n",
       " 'G3',\n",
       " 'D4',\n",
       " 'B3',\n",
       " 'E4',\n",
       " 'B-3',\n",
       " 'D4',\n",
       " 'A3',\n",
       " 'C#4',\n",
       " 'G#3',\n",
       " 'D4',\n",
       " 'G3',\n",
       " 'G4',\n",
       " 'F#3',\n",
       " 'B4',\n",
       " 'G3',\n",
       " 'E4',\n",
       " 'A3',\n",
       " 'F4',\n",
       " 'G#3',\n",
       " 'E4',\n",
       " 'G3',\n",
       " 'E-4',\n",
       " 'F#3',\n",
       " 'E4',\n",
       " 'G3',\n",
       " 'A4',\n",
       " 'F#3',\n",
       " 'A4',\n",
       " 'G3',\n",
       " 'A4',\n",
       " 'B4',\n",
       " 'C5',\n",
       " 'B4',\n",
       " 'F#3',\n",
       " 'A4',\n",
       " 'A4',\n",
       " 'D3',\n",
       " 'B4',\n",
       " 'A4',\n",
       " 'C3',\n",
       " 'A2',\n",
       " 'E4',\n",
       " 'C4',\n",
       " 'F4',\n",
       " 'B3',\n",
       " 'E4',\n",
       " 'B-3',\n",
       " 'E-4',\n",
       " 'A3',\n",
       " 'E4',\n",
       " 'G3',\n",
       " 'A4',\n",
       " 'F#3',\n",
       " 'C5',\n",
       " 'G3',\n",
       " 'D4',\n",
       " 'B3',\n",
       " 'E4',\n",
       " 'B-3',\n",
       " 'D4',\n",
       " 'A3',\n",
       " 'C#4',\n",
       " 'G#3',\n",
       " 'D4',\n",
       " 'G3',\n",
       " 'G4',\n",
       " 'F#3',\n",
       " 'B4',\n",
       " 'G3',\n",
       " 'E4',\n",
       " 'A3',\n",
       " 'F4',\n",
       " 'G#3',\n",
       " 'E4',\n",
       " 'G3',\n",
       " 'E-4',\n",
       " 'F#3',\n",
       " 'E4',\n",
       " 'G3',\n",
       " 'A4',\n",
       " 'F#3',\n",
       " 'A4',\n",
       " 'G3',\n",
       " 'A4',\n",
       " 'B4',\n",
       " 'C5',\n",
       " 'D5',\n",
       " 'F#3',\n",
       " 'C5',\n",
       " 'D5',\n",
       " 'A4',\n",
       " 'D3',\n",
       " 'B4',\n",
       " 'A4',\n",
       " 'B4',\n",
       " 'C5',\n",
       " 'E4',\n",
       " 'C3',\n",
       " 'E4',\n",
       " 'F4',\n",
       " 'F2',\n",
       " 'F4',\n",
       " 'F2',\n",
       " 'E4',\n",
       " 'C3',\n",
       " 'G4',\n",
       " 'F#4',\n",
       " 'G4',\n",
       " 'E4',\n",
       " 'C2',\n",
       " 'G4',\n",
       " 'C5',\n",
       " 'E5',\n",
       " 'E2',\n",
       " 'C5',\n",
       " 'B4',\n",
       " 'C5',\n",
       " 'B4',\n",
       " 'F2',\n",
       " 'A4',\n",
       " 'A4',\n",
       " 'E2',\n",
       " 'A4',\n",
       " 'G#4',\n",
       " 'A4',\n",
       " 'F4',\n",
       " 'D2',\n",
       " 'A4',\n",
       " 'D5',\n",
       " 'F5',\n",
       " 'F2',\n",
       " 'D5',\n",
       " 'C5',\n",
       " 'D5',\n",
       " 'C5',\n",
       " 'G2',\n",
       " 'B4',\n",
       " 'B4',\n",
       " 'F2',\n",
       " 'B4',\n",
       " 'B-4',\n",
       " 'B4',\n",
       " 'G4',\n",
       " 'E2',\n",
       " 'B4',\n",
       " 'E5',\n",
       " 'G5',\n",
       " 'G#2',\n",
       " 'F5',\n",
       " 'E5',\n",
       " 'G5',\n",
       " 'F5',\n",
       " 'A2',\n",
       " 'E5',\n",
       " 'E5',\n",
       " 'G2',\n",
       " 'D5',\n",
       " 'C5',\n",
       " 'E5',\n",
       " 'D5',\n",
       " 'F#2',\n",
       " 'C5',\n",
       " 'D5',\n",
       " 'A4',\n",
       " 'F#2',\n",
       " 'D5',\n",
       " 'C5',\n",
       " 'E5',\n",
       " 'D5',\n",
       " 'F2',\n",
       " 'C5',\n",
       " 'D5',\n",
       " 'A4',\n",
       " 'F2',\n",
       " 'D5',\n",
       " 'C5',\n",
       " 'E5',\n",
       " 'D5',\n",
       " 'E2',\n",
       " 'C5',\n",
       " 'D5',\n",
       " 'G4',\n",
       " 'E2',\n",
       " 'G4',\n",
       " 'C5',\n",
       " 'G5',\n",
       " 'G5',\n",
       " 'G2',\n",
       " 'F5',\n",
       " 'E5',\n",
       " 'F2',\n",
       " 'D5',\n",
       " 'A4',\n",
       " 'B4',\n",
       " 'E4',\n",
       " 'C2',\n",
       " 'G4',\n",
       " 'C5',\n",
       " 'E5',\n",
       " 'E2',\n",
       " 'C5',\n",
       " 'B4',\n",
       " 'C5',\n",
       " 'B4',\n",
       " 'F2',\n",
       " 'A4',\n",
       " 'A4',\n",
       " 'E2',\n",
       " 'A4',\n",
       " 'G#4',\n",
       " 'A4',\n",
       " 'F4',\n",
       " 'D2',\n",
       " 'A4',\n",
       " 'D5',\n",
       " 'F5',\n",
       " 'F2',\n",
       " 'D5',\n",
       " 'C5',\n",
       " 'D5',\n",
       " 'C5',\n",
       " 'G2',\n",
       " 'B4',\n",
       " 'B4',\n",
       " 'F2',\n",
       " 'B4',\n",
       " 'B-4',\n",
       " 'B4',\n",
       " 'G4',\n",
       " 'E2',\n",
       " 'B4',\n",
       " 'E5',\n",
       " 'G5',\n",
       " 'G#2',\n",
       " 'F5',\n",
       " 'E5',\n",
       " 'G5',\n",
       " 'F5',\n",
       " 'A2',\n",
       " 'E5',\n",
       " 'E5',\n",
       " 'G2',\n",
       " 'D5',\n",
       " 'C5',\n",
       " 'E5',\n",
       " 'D5',\n",
       " 'F#2',\n",
       " 'C5',\n",
       " 'D5',\n",
       " 'A4',\n",
       " 'F#2',\n",
       " 'D5',\n",
       " 'C5',\n",
       " 'E5',\n",
       " 'D5',\n",
       " 'F2',\n",
       " 'C5',\n",
       " 'D5',\n",
       " 'A4',\n",
       " 'F2',\n",
       " 'B4',\n",
       " 'G2',\n",
       " 'A4',\n",
       " 'B4',\n",
       " 'G2',\n",
       " 'C5',\n",
       " 'C2',\n",
       " 'C5',\n",
       " 'C2',\n",
       " 'C5',\n",
       " 'C2',\n",
       " 'C5',\n",
       " 'C2',\n",
       " 'C5',\n",
       " 'C2',\n",
       " 'G5',\n",
       " 'G5',\n",
       " 'G5',\n",
       " 'E4',\n",
       " 'C4',\n",
       " 'F4',\n",
       " 'B3',\n",
       " 'E4',\n",
       " 'B-3',\n",
       " 'E-4',\n",
       " 'A3',\n",
       " 'E4',\n",
       " 'G3',\n",
       " 'A4',\n",
       " 'F#3',\n",
       " 'C5',\n",
       " 'G3',\n",
       " 'D4',\n",
       " 'B3',\n",
       " 'E4',\n",
       " 'B-3',\n",
       " 'D4',\n",
       " 'A3',\n",
       " 'C#4',\n",
       " 'G#3',\n",
       " 'D4',\n",
       " 'G3',\n",
       " 'G4',\n",
       " 'F#3',\n",
       " 'B4',\n",
       " 'G3',\n",
       " 'E4',\n",
       " 'A3',\n",
       " 'F4',\n",
       " 'G#3',\n",
       " 'E4',\n",
       " 'G3',\n",
       " 'E-4',\n",
       " 'F#3',\n",
       " 'E4',\n",
       " 'G3',\n",
       " 'A4',\n",
       " 'F#3',\n",
       " 'A4',\n",
       " 'G3',\n",
       " 'A4',\n",
       " 'B4',\n",
       " 'C5',\n",
       " 'B4',\n",
       " 'F#3',\n",
       " 'A4',\n",
       " 'A4',\n",
       " 'D3',\n",
       " 'B4',\n",
       " 'A4',\n",
       " 'C3',\n",
       " 'A2',\n",
       " 'E4',\n",
       " 'C4',\n",
       " 'F4',\n",
       " 'B3',\n",
       " 'E4',\n",
       " 'B-3',\n",
       " 'E-4',\n",
       " 'A3',\n",
       " 'E4',\n",
       " 'G3',\n",
       " 'A4',\n",
       " 'F#3',\n",
       " 'C5',\n",
       " 'G3',\n",
       " 'D4',\n",
       " 'B3',\n",
       " 'E4',\n",
       " 'B-3',\n",
       " 'D4',\n",
       " 'A3',\n",
       " 'C#4',\n",
       " 'G#3',\n",
       " 'D4',\n",
       " 'G3',\n",
       " 'G4',\n",
       " 'F#3',\n",
       " 'B4',\n",
       " 'G3',\n",
       " 'E4',\n",
       " 'A3',\n",
       " 'F4',\n",
       " 'G#3',\n",
       " 'E4',\n",
       " 'G3',\n",
       " 'E-4',\n",
       " 'F#3',\n",
       " 'E4',\n",
       " 'G3',\n",
       " 'A4',\n",
       " 'F#3',\n",
       " 'A4',\n",
       " 'G3',\n",
       " 'A4',\n",
       " 'B4',\n",
       " 'C5',\n",
       " 'D5',\n",
       " 'F#3',\n",
       " 'C5',\n",
       " 'D5',\n",
       " 'A4',\n",
       " 'D3',\n",
       " 'B4',\n",
       " 'A4',\n",
       " 'B4',\n",
       " 'C5',\n",
       " 'E4',\n",
       " 'C3',\n",
       " 'E4',\n",
       " 'F4',\n",
       " 'F2',\n",
       " 'F4',\n",
       " 'F2',\n",
       " 'E4',\n",
       " 'C3',\n",
       " 'G4',\n",
       " 'F#4',\n",
       " 'G4',\n",
       " 'E4',\n",
       " 'C2',\n",
       " 'G4',\n",
       " 'C5',\n",
       " 'E5',\n",
       " 'E2',\n",
       " 'C5',\n",
       " 'B4',\n",
       " 'C5',\n",
       " 'B4',\n",
       " 'F2',\n",
       " 'A4',\n",
       " 'A4',\n",
       " 'E2',\n",
       " 'A4',\n",
       " 'G#4',\n",
       " 'A4',\n",
       " 'F4',\n",
       " 'D2',\n",
       " 'A4',\n",
       " 'D5',\n",
       " 'F5',\n",
       " 'F2',\n",
       " 'D5',\n",
       " 'C5',\n",
       " 'D5',\n",
       " 'C5',\n",
       " 'G2',\n",
       " 'B4',\n",
       " 'B4',\n",
       " 'F2',\n",
       " 'B4',\n",
       " 'B-4',\n",
       " 'B4',\n",
       " 'G4',\n",
       " 'E2',\n",
       " 'B4',\n",
       " 'E5',\n",
       " 'G5',\n",
       " 'G#2',\n",
       " 'F5',\n",
       " 'E5',\n",
       " 'G5',\n",
       " 'F5',\n",
       " 'A2',\n",
       " 'E5',\n",
       " 'E5',\n",
       " 'G2',\n",
       " 'D5',\n",
       " 'C5',\n",
       " 'E5',\n",
       " 'D5',\n",
       " 'F#2',\n",
       " 'C5',\n",
       " 'D5',\n",
       " 'A4',\n",
       " 'F#2',\n",
       " 'D5',\n",
       " 'C5',\n",
       " 'E5',\n",
       " 'D5',\n",
       " 'F2',\n",
       " 'C5',\n",
       " 'D5',\n",
       " 'A4',\n",
       " 'F2',\n",
       " 'D5',\n",
       " 'C5',\n",
       " 'E5',\n",
       " 'D5',\n",
       " 'E2',\n",
       " 'C5',\n",
       " 'D5',\n",
       " 'G4',\n",
       " 'E2',\n",
       " 'G4',\n",
       " 'C5',\n",
       " 'G5',\n",
       " 'G5',\n",
       " 'G2',\n",
       " 'F5',\n",
       " 'E5',\n",
       " 'F2',\n",
       " 'D5',\n",
       " 'A4',\n",
       " 'B4',\n",
       " 'E4',\n",
       " 'C2',\n",
       " 'G4',\n",
       " 'C5',\n",
       " 'E5',\n",
       " 'E2',\n",
       " 'C5',\n",
       " 'B4',\n",
       " 'C5',\n",
       " 'B4',\n",
       " 'F2',\n",
       " 'A4',\n",
       " 'A4',\n",
       " 'E2',\n",
       " 'A4',\n",
       " 'G#4',\n",
       " 'A4',\n",
       " 'F4',\n",
       " 'D2',\n",
       " 'A4',\n",
       " 'D5',\n",
       " 'F5',\n",
       " 'F2',\n",
       " 'D5',\n",
       " 'C5',\n",
       " 'D5',\n",
       " 'C5',\n",
       " 'G2',\n",
       " 'B4',\n",
       " 'B4',\n",
       " 'F2',\n",
       " 'B4',\n",
       " 'B-4',\n",
       " 'B4',\n",
       " 'G4',\n",
       " 'E2',\n",
       " 'B4',\n",
       " 'E5',\n",
       " 'G5',\n",
       " 'G#2',\n",
       " 'F5',\n",
       " 'E5',\n",
       " 'G5',\n",
       " 'F5',\n",
       " 'A2',\n",
       " 'E5',\n",
       " 'E5',\n",
       " 'G2',\n",
       " 'D5',\n",
       " 'C5',\n",
       " 'E5',\n",
       " 'D5',\n",
       " 'F#2',\n",
       " 'C5',\n",
       " 'D5',\n",
       " 'A4',\n",
       " 'F#2',\n",
       " 'D5',\n",
       " 'C5',\n",
       " 'E5',\n",
       " 'D5',\n",
       " 'F2',\n",
       " 'C5',\n",
       " 'D5',\n",
       " 'A4',\n",
       " 'F2',\n",
       " 'B4',\n",
       " 'G2',\n",
       " 'A4',\n",
       " 'B4',\n",
       " 'G2',\n",
       " 'C5',\n",
       " 'C2',\n",
       " 'C5',\n",
       " 'C2',\n",
       " 'C5',\n",
       " 'C2',\n",
       " 'C5',\n",
       " 'C2',\n",
       " ...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_notes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "THY-sZMiQ4UV"
   },
   "source": [
    "## Create the models\n",
    "\n",
    "Both the generator and discriminator are defined using the [Keras Sequential API](https://www.tensorflow.org/guide/keras#sequential_model)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-tEyxE-GMC48"
   },
   "source": [
    "### The Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of latent space for the model to work with\n",
    "LATENT_DIM = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6bpTcDqoLWjY"
   },
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(256, input_dim=LATENT_DIM))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.BatchNormalization(momentum=0.8))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(512))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.BatchNormalization(momentum=0.8))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(1024))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.BatchNormalization(momentum=0.8))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(np.prod(SEQ_INPUT_SHAPE), activation='tanh'))\n",
    "    model.add(layers.Reshape(SEQ_INPUT_SHAPE))\n",
    "    model.summary()\n",
    "    \n",
    "    noise = Input(shape=(LATENT_DIM,))\n",
    "    seq = model(noise)\n",
    "\n",
    "    return Model(noise, seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D0IKnaCtg6WE"
   },
   "source": [
    "### The Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dw2tPLmk2pEP"
   },
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.LSTM(512, input_shape=SEQ_INPUT_SHAPE, return_sequences=True))\n",
    "    model.add(layers.Bidirectional(layers.LSTM(512)))\n",
    "    model.add(layers.Dense(512))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(256))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.summary()\n",
    "    \n",
    "    seq = Input(shape=SEQ_INPUT_SHAPE)\n",
    "    validity = model(seq)\n",
    "\n",
    "    return Model(seq, validity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN (Generator + Discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100, 512)          1052672   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 1024)              4198400   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 5,907,457\n",
      "Trainable params: 5,907,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 256)               6656      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               102500    \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 100, 1)            0         \n",
      "=================================================================\n",
      "Total params: 773,220\n",
      "Trainable params: 769,636\n",
      "Non-trainable params: 3,584\n",
      "_________________________________________________________________\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 25)]              0         \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 100, 1)            773220    \n",
      "_________________________________________________________________\n",
      "model (Model)                (None, 1)                 5907457   \n",
      "=================================================================\n",
      "Total params: 6,680,677\n",
      "Trainable params: 769,636\n",
      "Non-trainable params: 5,911,041\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "# Build and compile the discriminator\n",
    "discriminator = build_discriminator()\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Build the generator\n",
    "generator = build_generator()\n",
    "\n",
    "# The generator takes noise as input and generates note sequences\n",
    "z = Input(shape=(LATENT_DIM,))\n",
    "generated_seq = generator(z)\n",
    "\n",
    "# For the combined model we will only train the generator\n",
    "discriminator.trainable = False\n",
    "\n",
    "# The discriminator takes generated images as input and determines validity\n",
    "validity = discriminator(generated_seq)\n",
    "\n",
    "# The combined model  (stacked generator and discriminator)\n",
    "# Trains the generator to fool the discriminator\n",
    "gan = Model(z, validity)\n",
    "gan.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rw1fkAczTQYh"
   },
   "source": [
    "## Define the training loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NS2GWywBbAWo"
   },
   "outputs": [],
   "source": [
    "# number of iterations to run the network\n",
    "EPOCHS = 50\n",
    "# number of sequences of length SEQ_INPUT_LEN that will be used as training data\n",
    "BATCH_SIZE = 128\n",
    "# interval for saving checkpoints\n",
    "SAMPLING_INTERVAL = 10\n",
    "\n",
    "disc_loss = []\n",
    "gen_loss = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jylSonrqSWfi"
   },
   "source": [
    "The training loop begins with generator receiving a random seed as input. That seed is used to produce an image. The discriminator is then used to classify real images (drawn from the training set) and fakes images (produced by the generator). The loss is calculated for each of these models, and the gradients are used to update the generator and discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2M7LmLtGEMQJ"
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    # Load and convert the data\n",
    "    notes = pickle.load(open('notes.p', 'rb'))\n",
    "    n_vocab = len(set(notes))\n",
    "    network_input, network_output = prepare_sequences(notes, n_vocab)\n",
    "\n",
    "    # Adversarial ground truths\n",
    "    real = np.ones((BATCH_SIZE, 1))\n",
    "    fake = np.zeros((BATCH_SIZE, 1))\n",
    "\n",
    "    # Training the model\n",
    "    for epoch in range(EPOCHS):\n",
    "\n",
    "        # Training the discriminator\n",
    "        # Select a random batch of note sequences\n",
    "        idx = np.random.randint(0, network_input.shape[0], BATCH_SIZE)\n",
    "        real_seqs = network_input[idx]\n",
    "\n",
    "        noise = np.random.normal(0, 1, (BATCH_SIZE, LATENT_DIM))\n",
    "\n",
    "        # Generate a batch of new note sequences\n",
    "        gen_seqs = generator.predict(noise)\n",
    "\n",
    "        # Train the discriminator\n",
    "        d_loss_real = discriminator.train_on_batch(real_seqs, real)\n",
    "        d_loss_fake = discriminator.train_on_batch(gen_seqs, fake)\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "        #  Training the Generator\n",
    "        noise = np.random.normal(0, 1, (BATCH_SIZE, LATENT_DIM))\n",
    "\n",
    "        # Train the generator (to have the discriminator label samples as real)\n",
    "        g_loss = gan.train_on_batch(noise, real)\n",
    "\n",
    "        # Print the progress and save into loss lists\n",
    "        if (epoch + 1) % SAMPLING_INTERVAL == 0:\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "            disc_loss.append(d_loss[0])\n",
    "            gen_loss.append(g_loss)\n",
    "        \n",
    "    # Generate after the final epoch\n",
    "    generate_and_save_midi(notes)\n",
    "    plot_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2aFF7Hk3XdeW"
   },
   "source": [
    "**Generate MIDI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_midi(notes):\n",
    "    # Get pitch names and store in a dictionary\n",
    "    notes = pickle.load(open('notes.p', 'rb'))\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    # Use random noise to generate sequences\n",
    "    noise = np.random.normal(0, 1, (1, LATENT_DIM))\n",
    "    predictions = generator.predict(noise)\n",
    "    \n",
    "    pred_notes = [min(len(pitchnames)-1, np.abs(x*len(pitchnames))) for x in predictions[0]]\n",
    "    pred_notes = [int_to_note[int(x)] for x in pred_notes]\n",
    "    \n",
    "    create_midi(pred_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RmdVsmvhPxyy"
   },
   "outputs": [],
   "source": [
    "def create_midi(prediction_output):\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "    for pattern in prediction_output:\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                new_note = note.Note(int(current_note))\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "        else:\n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "        offset += 0.5\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    midi_stream.write('midi', fp='gan_output.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot Losses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss():\n",
    "    plt.plot(disc_loss, c='red')\n",
    "    plt.plot(gen_loss, c='blue')\n",
    "    plt.title(\"GAN Loss per Epoch\")\n",
    "    plt.legend(['Discriminator', 'Generator'])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.savefig('GAN_Loss_per_Epoch_final.png', transparent=True)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dZrd4CdjR-Fp"
   },
   "source": [
    "## Train the model\n",
    "Call the `train()` method defined above to train the generator and discriminator simultaneously. Note, training GANs can be tricky. It's important that the generator and discriminator do not overpower each other (e.g., that they train at a similar rate).\n",
    "\n",
    "At the beginning of the training, the generated images look like random noise. As training progresses, the generated digits will look increasingly real. After about 50 epochs, they resemble MNIST digits. This may take about one minute / epoch with the default settings on Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ly3UN0SLLY2l"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 [D loss: 0.588488, acc.: 63.67%] [G loss: 0.785792]\n",
      "19 [D loss: 0.654489, acc.: 62.11%] [G loss: 0.901782]\n",
      "29 [D loss: 0.684950, acc.: 58.59%] [G loss: 1.015698]\n",
      "39 [D loss: 0.705766, acc.: 50.39%] [G loss: 0.837107]\n",
      "49 [D loss: 0.693023, acc.: 48.83%] [G loss: 0.853782]\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k6qC-SbjK0yW"
   },
   "source": [
    "# Experimentation + Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xjjkT9KAK6H7"
   },
   "source": [
    "## Iteration 0: Adaptation of Tutorial\n",
    "\n",
    "In iteration 0 of the network, I adapted the code provided in the tutorial to work with the Mario MIDI files.\n",
    "\n",
    "### Results:\n",
    "![iteration_0](initial_output/GAN_Loss_per_Epoch_final_initial.png \"iteration_0\")\n",
    "\n",
    "Audio: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteration 1: Dropout Layers in Generator\n",
    "\n",
    "In iteration 1, I looked to the RNN construction in Assignment 3 for inspiration on how to modify my current generator. I decided on included several Dropout layers.\n",
    "\n",
    "### Results:\n",
    "![iteration_1](dropout_gen_output/GAN_Loss_per_Epoch_final_dropout_gen.png \"iteration_1\")\n",
    "\n",
    "Audio: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteration 2: Dropout Layers in Generator and Discriminator\n",
    "\n",
    "In iteration 2, I thought back to the idea that the generator and discriminator should be learning at the same rate so that one doesn't overpower the other. I wondered if the dropout layers added to the generator did help it learn faster and that the discriminator was falling behind. I tested this hypothesis by adding Dropout layers to both the generator and discriminator.\n",
    "\n",
    "### Results:\n",
    "![iteration_2](dropout_gen_dis_output/GAN_Loss_per_Epoch_final_dropout_gen_dis.png \"iteration_2\")\n",
    "\n",
    "Audio: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Overall, this a challenging yet fun project to work on. If I had more time, I'd want to revisit this prompt and consider pursuing some of the following paths:\n",
    "* train the network with more Mario MIDI files\n",
    "* preprocess the MIDI files to separate instruments\n",
    "* group Mario songs that have a similar mood\n",
    "* create new encoding that considers rhythm\n",
    "* experiment with different layer types\n",
    "* explore other papers on GAN music generation"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "dcgan.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
